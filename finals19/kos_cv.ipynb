{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(y_true, y_predict, shift=0):\n",
    "    return 2 * np.mean(\n",
    "        np.abs(y_true - y_predict) /\n",
    "        (np.abs(y_true) + np.abs(y_predict) + shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE_log(y_predict, y_true):\n",
    "    if isinstance(y_true, lgb.Dataset):\n",
    "        y_true = y_true.label\n",
    "    y_true = np.expm1(y_true)\n",
    "    y_predict = np.expm1(y_predict)\n",
    "    return ('sMAPE', 2 * np.mean(\n",
    "        np.abs(y_true - y_predict) /\n",
    "        (np.abs(y_true) + np.abs(y_predict))),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 00:01:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 00:02:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 00:03:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 00:04:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  num_orders\n",
       "0 2018-03-01 00:00:00           0\n",
       "1 2018-03-01 00:01:00           0\n",
       "2 2018-03-01 00:02:00           0\n",
       "3 2018-03-01 00:03:00           0\n",
       "4 2018-03-01 00:04:00           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_name = 'set1'\n",
    "path_train_set = 'taxi-idao/data/train/{}.csv'.format(set_name)\n",
    "\n",
    "data = pd.read_csv(path_train_set)\n",
    "data.datetime = data.datetime.apply(\n",
    "    lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "data = data.sort_values('datetime')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 30, 45, 60, 75]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_positions = {\n",
    "    'set1': [10, 30, 45, 60, 75],\n",
    "    'set2': [5, 10, 15, 20, 25],\n",
    "    'set3': [5, 7, 9, 11, 13]\n",
    "}[set_name]\n",
    "target_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUR_IN_MINUTES = 60\n",
    "DAY_IN_MINUTES = 24 * HOUR_IN_MINUTES\n",
    "WEEK_IN_MINUTES = 7 * DAY_IN_MINUTES\n",
    "\n",
    "MAX_TIME = DAY_IN_MINUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "    'datetime': [],\n",
    "    'history': []}\n",
    "\n",
    "for position in target_positions:\n",
    "    samples['target_{}'.format(position)] = []\n",
    "    \n",
    "num_orders = data.num_orders.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start after 2 weeks because of history\n",
    "# finish earlier because of target calculation\n",
    "for i in range(2 * WEEK_IN_MINUTES,\n",
    "               len(num_orders) - 2 * DAY_IN_MINUTES):\n",
    "    \n",
    "    samples['datetime'].append(data.datetime[i])\n",
    "    samples['history'].append(num_orders[i-2*WEEK_IN_MINUTES:i])\n",
    "    \n",
    "    # cumsum not for all array because of time economy\n",
    "    cumsum_num_orders = num_orders[i+1:i+1+2*DAY_IN_MINUTES].cumsum()\n",
    "    for position in target_positions:\n",
    "        orders_by_positions = np.where(cumsum_num_orders >= position)[0]\n",
    "        if len(orders_by_positions):\n",
    "            time = orders_by_positions[0] + 1\n",
    "        else:\n",
    "            # if no orders in last days\n",
    "            time = MAX_TIME\n",
    "        samples['target_{}'.format(position)].append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime 241920\n",
      "target_60 241920\n",
      "target_75 241920\n",
      "target_30 241920\n",
      "target_45 241920\n",
      "target_10 241920\n",
      "history 241920\n"
     ]
    }
   ],
   "source": [
    "for k in samples.keys():\n",
    "    print(k, len(samples[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df.datetime.apply(lambda x: x.weekday())\n",
    "df['hour'] = df.datetime.apply(lambda x: x.hour)\n",
    "df['minute'] = df.datetime.apply(lambda x: x.minute)\n",
    "df['daymin_sin'] = np.sin(2 * np.pi * (df['hour']*60 + df.minute)/1440.0)\n",
    "df['daymin_cos'] = np.cos(2 * np.pi * (df['hour']*60 + df.minute)/1440.0)\n",
    "df['weekday'] = df['weekday'].astype('category')\n",
    "df = df.drop(['hour','minute'], axis=1)\n",
    "\n",
    "df['dch'] = df.datetime.apply(lambda x: str(x.hour) + ' ' + str(x.weekday()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_ewm_alpha_v1(a,wghts):\n",
    "    out = np.dot(a,wghts)\n",
    "    return out\n",
    "\n",
    "wsize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wghts01 = (1-0.01)**np.arange(wsize)\n",
    "wghts01 /= wghts01.sum()\n",
    "wghts01 = wghts01[::-1]\n",
    "\n",
    "wghts05 = (1-0.05)**np.arange(wsize)\n",
    "wghts05 /= wghts05.sum()\n",
    "wghts05 = wghts05[::-1]\n",
    "\n",
    "\n",
    "wghts1 = (1-0.1)**np.arange(wsize)\n",
    "wghts1 /= wghts1.sum()\n",
    "wghts1 = wghts1[::-1]\n",
    "\n",
    "\n",
    "wghts2 = (1-0.2)**np.arange(wsize)\n",
    "wghts2 /= wghts2.sum()\n",
    "wghts2 = wghts2[::-1]\n",
    "\n",
    "wghts001 = (1-0.001)**np.arange(wsize)\n",
    "wghts001 /= wghts001.sum()\n",
    "wghts001 = wghts001[::-1]\n",
    "\n",
    "wghts005 = (1-0.005)**np.arange(wsize)\n",
    "wghts005 /= wghts005.sum()\n",
    "wghts005 = wghts005[::-1]\n",
    "\n",
    "df['exp_{}'.format(0.01)] = df.history.apply(lambda x: numpy_ewm_alpha_v1(x[-wsize:],wghts01))\n",
    "df['exp_{}'.format(0.05)] = df.history.apply(lambda x: numpy_ewm_alpha_v1(x[-wsize:],wghts05))\n",
    "df['exp_{}'.format(0.1)] = df.history.apply(lambda x: numpy_ewm_alpha_v1(x[-wsize:],wghts1))\n",
    "df['exp_{}'.format(0.2)] = df.history.apply(lambda x: numpy_ewm_alpha_v1(x[-wsize:],wghts2))\n",
    "df['exp_{}'.format(0.001)] = df.history.apply(lambda x: numpy_ewm_alpha_v1(x[-wsize:],wghts001))\n",
    "df['exp_{}'.format(0.005)] = df.history.apply(lambda x: numpy_ewm_alpha_v1(x[-wsize:],wghts005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dch_enc_dict = {k: df.groupby('dch')['target_{}'.format(k)].mean() for k in target_positions}\n",
    "\n",
    "# for position in target_positions:\n",
    "#     df['dch_enc_{}'.format(position)] = df['dch'].map(model_to_save['encs'][position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFTS = [\n",
    "    HOUR_IN_MINUTES // 4,\n",
    "    HOUR_IN_MINUTES // 2,\n",
    "    HOUR_IN_MINUTES,\n",
    "    DAY_IN_MINUTES,\n",
    "    DAY_IN_MINUTES * 2,\n",
    "    WEEK_IN_MINUTES,\n",
    "    WEEK_IN_MINUTES * 2]\n",
    "WINDOWS = [\n",
    "    HOUR_IN_MINUTES // 4,\n",
    "    HOUR_IN_MINUTES // 2,\n",
    "    HOUR_IN_MINUTES,\n",
    "    DAY_IN_MINUTES,\n",
    "    DAY_IN_MINUTES * 2,\n",
    "    WEEK_IN_MINUTES,\n",
    "    WEEK_IN_MINUTES * 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block = []\n",
    "# block.append((60,30))\n",
    "# block.append((60,15))\n",
    "# block.append((30,30))\n",
    "# block.append((30,15))\n",
    "# block.append((15,15))\n",
    "# block.append((2880,60))\n",
    "# block.append((2880,30))\n",
    "# block.append((2880,15))\n",
    "# block.append((20160,30))\n",
    "# block.append((20160,15))\n",
    "# block.append((10080,30))\n",
    "# block.append((10080,15))\n",
    "# block.append((1440,30))\n",
    "# block.append((1440,15))\n",
    "# block = set(block)\n",
    "\n",
    "# for shift in tqdm(SHIFTS):\n",
    "#     for window in WINDOWS:\n",
    "#         if window > shift or (shift,window) in block:\n",
    "#             continue\n",
    "#         right = -shift + window\n",
    "#         if right == 0:\n",
    "#             right = None\n",
    "        \n",
    "#         df['num_orders_{}_{}'.format(shift, window)] = \\\n",
    "#             df.history.apply(lambda x: x[-shift : right].sum())\n",
    "#         df['num_orders_{}_{}_mean'.format(shift, window)] = \\\n",
    "#             df.history.apply(lambda x: x[-shift : right].mean())\n",
    "#         df['num_orders_{}_{}_std'.format(shift, window)] = \\\n",
    "#             df.history.apply(lambda x: x[-shift : right].std())\n",
    "# #         df['num_orders_{}_{}_skew'.format(shift, window)] = \\\n",
    "# #             df.history.apply(lambda x: x[-shift : -shift + window].skew())\n",
    "#         df['num_orders_{}_{}_min'.format(shift, window)] = \\\n",
    "#             df.history.apply(lambda x: x[-shift : right].min())\n",
    "#         df['num_orders_{}_{}_max'.format(shift, window)] = \\\n",
    "#             df.history.apply(lambda x: x[-shift : right].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:13<00:00, 13.17s/it]\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "arr.append((10080,60))\n",
    "arr.append((20160,60))\n",
    "arr.append((2880,60))\n",
    "arr.append((1440,60))\n",
    "arr.append((1440,1440))\n",
    "arr.append((2880,2880))\n",
    "arr.append((10080,10080))\n",
    "arr.append((20160,20160))\n",
    "\n",
    "# for shift in SHIFTS:\n",
    "#     for window in WINDOWS:\n",
    "for shift,window in tqdm(arr):\n",
    "        if window > shift:\n",
    "            continue\n",
    "        right = -shift + window\n",
    "        right = -1 if right == 0 else right\n",
    "        df['num_orders_{}_{}'.format(shift, window)] = \\\n",
    "            df.history.apply(lambda x: x[-shift : right].sum())\n",
    "        df['num_orders_{}_{}_std'.format(shift, window)] = \\\n",
    "            df.history.apply(lambda x: x[-shift : right].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=442)\n",
    "# ts = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['target_{}'.format(position) for position in target_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'objective': 'mae',\n",
    "        'metric': 'mae',\n",
    "        'learning_rate': 0.05,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"feature_fraction\": 0.8,\n",
    "#         \"min_sum_hessian_in_leaf\": 10,\n",
    "        \"num_threads\": 15,\n",
    "        \"lambda_l1\": 10.,\n",
    "        \"lambda_l2\": 10.,\n",
    "#         \"min_split_gain\": 1.,\n",
    "        \"min_data_in_leaf\": 1000,\n",
    "        \"num_leaves\" : 150,\n",
    "#         'max_depth':5,\n",
    "        \"use_two_round_loading\": False,\n",
    "#         \"histogram_pool_size\": 1024*100,\n",
    "#         'bin_construct_sample_cnt':10000000,\n",
    "        \"reg_sqrt\": False\n",
    "   }\n",
    "parameters = {'feature_fraction': 0.6532271360402252,\n",
    "              'learning_rate': 0.020208933466333873,\n",
    "              'lambda_l1': 2.3258779081081675,\n",
    "              'lambda_l2': 2.3258779081081675,\n",
    "              'min_data_in_leaf': 750,\n",
    "              'bagging_fraction': 0.5931454235914756,\n",
    "              'num_leaves': 20,\n",
    "              'objective': 'mae',\n",
    "              'metric': 'mae',\n",
    "              'bagging_freq': 2,\n",
    "              'num_threads': 15,\n",
    "              'reg_sqrt': True\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_use = df.loc[df.datetime.dt.month >= 5].copy()\n",
    "df_use = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = {\n",
    "    'models': {},\n",
    "    'encs': {k: {} for k in target_positions}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.groupby('dch')['target_{}'.format(k)].mean()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n.prokoptsev/.local/lib/python3.5/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 complete\n",
      "fold 2 complete\n",
      "fold 3 complete\n",
      "fold 4 complete\n",
      "fold 5 complete\n",
      "target_10\n",
      "stupid:\t0.5717447627854316\n",
      "model:\t0.32095100002378435\n",
      "\n",
      "target_30\n",
      "stupid:\t0.4319931479991387\n",
      "model:\t0.25436133819973905\n",
      "\n",
      "target_45\n",
      "stupid:\t0.40888033307558536\n",
      "model:\t0.23138480874785441\n",
      "\n",
      "target_60\n",
      "stupid:\t0.39144963971394\n",
      "model:\t0.214915389288443\n",
      "\n",
      "target_75\n",
      "stupid:\t0.3781095560663338\n",
      "model:\t0.20135148354337412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = {k:[] for k in target_positions}\n",
    "fold_no = 1\n",
    "for tr_ix, val_ix in kf.split(df_use):\n",
    "    \n",
    "    for position in target_positions:\n",
    "#         df_use['dch_enc'] = df_use['dch'].map(model_to_save['encs'][position])\n",
    "        df_train = df_use.iloc[tr_ix]\n",
    "        df_test = df_use.iloc[val_ix]\n",
    "\n",
    "        y_train = df_train[target_cols]\n",
    "    #     y_train_log = np.log1p(y_train)\n",
    "        y_test = df_test[target_cols]\n",
    "    #     y_test_log = np.log1p(y_test)\n",
    "        df_train_pos = df_train.drop(['datetime', 'history', 'dch'] + target_cols, axis=1)\n",
    "        df_test_pos = df_test.drop(['datetime', 'history', 'dch'] + target_cols, axis=1)\n",
    "        \n",
    "        train_dataset = lgb.Dataset(df_train_pos, y_train['target_{}'.format(position)])\n",
    "        test_dataset = lgb.Dataset(df_test_pos, y_test['target_{}'.format(position)])\n",
    "        model = lgb.train(parameters,\n",
    "                          train_dataset,\n",
    "                          valid_sets=(train_dataset, test_dataset),\n",
    "                          early_stopping_rounds=20,\n",
    "                          verbose_eval=0,\n",
    "                          num_boost_round=500,\n",
    "#                           feval=sMAPE_log\n",
    "                         )\n",
    "        y_predict = model.predict(df_test_pos)\n",
    "#         y_predict = np.expm1(y_predict)\n",
    "        \n",
    "        score = sMAPE(y_test['target_{}'.format(position)], y_predict)\n",
    "        scores[position].append(score)\n",
    "        \n",
    "    print('fold {} complete'.format(fold_no))\n",
    "    fold_no += 1\n",
    "for position in target_positions:\n",
    "    print('target_{}'.format(position))\n",
    "    print('stupid:\\t{}'.format(sMAPE(\n",
    "        y_test['target_{}'.format(position)],\n",
    "        y_train['target_{}'.format(position)].median())))\n",
    "    print('model:\\t{}'.format(np.mean(scores[position])))\n",
    "    print()\n",
    "    \n",
    "#     df_use['dch_enc'] = df_use['dch'].map(model_to_save['encs'][position])\n",
    "    df_train, df_test = train_test_split(df_use, test_size=.2, random_state=442, shuffle=True)\n",
    "    y_train = df_train[target_cols]\n",
    "    y_test = df_test[target_cols]\n",
    "    df_train_pos = df_train.drop(['datetime', 'history', 'dch'] + target_cols, axis=1)\n",
    "    df_test_pos = df_test.drop(['datetime', 'history', 'dch'] + target_cols, axis=1)\n",
    "    \n",
    "    train_dataset = lgb.Dataset(df_train_pos, y_train['target_{}'.format(position)])\n",
    "    test_dataset = lgb.Dataset(df_test_pos, y_test['target_{}'.format(position)])\n",
    "    model = lgb.train(parameters,\n",
    "                          train_dataset,\n",
    "                          valid_sets=(train_dataset, test_dataset),\n",
    "                          early_stopping_rounds=20,\n",
    "                          verbose_eval=0,\n",
    "                          num_boost_round=500)    \n",
    "    model_to_save['models'][position] = model\n",
    "pickle.dump(model_to_save, open('model_kos/models_lgb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weekday', 'daymin_sin', 'daymin_cos', 'exp_0.01', 'exp_0.05',\n",
       "       'exp_0.1', 'exp_0.2', 'exp_0.001', 'exp_0.005', 'num_orders_10080_60',\n",
       "       'num_orders_10080_60_std', 'num_orders_20160_60',\n",
       "       'num_orders_20160_60_std', 'num_orders_2880_60',\n",
       "       'num_orders_2880_60_std', 'num_orders_1440_60',\n",
       "       'num_orders_1440_60_std', 'num_orders_1440_1440',\n",
       "       'num_orders_1440_1440_std', 'num_orders_2880_2880',\n",
       "       'num_orders_2880_2880_std', 'num_orders_10080_10080',\n",
       "       'num_orders_10080_10080_std', 'num_orders_20160_20160',\n",
       "       'num_orders_20160_20160_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_10\n",
    "stupid:\t0.5717447627854316\n",
    "model:\t0.318513210266847\n",
    "\n",
    "target_30\n",
    "stupid:\t0.4319931479991387\n",
    "model:\t0.252706549564262\n",
    "\n",
    "target_45\n",
    "stupid:\t0.40888033307558536\n",
    "model:\t0.23051693567073003\n",
    "\n",
    "target_60\n",
    "stupid:\t0.39144963971394\n",
    "model:\t0.21356155804815974\n",
    "\n",
    "target_75\n",
    "stupid:\t0.3781095560663338\n",
    "model:\t0.20052793366470678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_5\n",
    "stupid:\t0.7257808547638245\n",
    "model:\t0.4998490851153359\n",
    "\n",
    "target_10\n",
    "stupid:\t0.6608281056458376\n",
    "model:\t0.4019303165728233\n",
    "\n",
    "target_15\n",
    "stupid:\t0.5927615840829038\n",
    "model:\t0.33823548020795857\n",
    "\n",
    "target_20\n",
    "stupid:\t0.5421014104769756\n",
    "model:\t0.301166912871263\n",
    "\n",
    "target_25\n",
    "stupid:\t0.502216363688881\n",
    "model:\t0.27612079609550644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
